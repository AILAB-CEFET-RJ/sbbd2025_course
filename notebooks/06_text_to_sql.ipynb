{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Text-to-SQL Pipeline\n",
        "\n",
        "## Learning Goals\n",
        "- Understand the components of a **Text-to-SQL** pipeline.\n",
        "- Use an LLM to generate SQL queries from natural language questions.\n",
        "- Execute queries on a sample SQLite database.\n",
        "- Implement a correction loop when SQL fails.\n",
        "- Return results in natural language.\n",
        "\n",
        "This notebook corresponds to Section *1.7 Text-to-SQL* in the lecture notes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %load get_llm.py\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "\n",
        "# Load environment variables from .env\n",
        "load_dotenv()\n",
        "\n",
        "def get_llm(provider: str = \"openai\"):\n",
        "    \"\"\"\n",
        "    Return a language model instance configured for either OpenAI or Ollama.\n",
        "\n",
        "    This function centralizes the initialization of chat-based LLMs so that \n",
        "    notebooks and applications can switch seamlessly between cloud-based models \n",
        "    (OpenAI) and local models (Ollama).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    provider : str, optional\n",
        "        The backend provider to use. Options are:\n",
        "        - \"openai\": returns a ChatOpenAI instance (requires OPENAI_API_KEY in .env).\n",
        "        - \"ollama\": returns a ChatOllama instance (requires Ollama installed locally).\n",
        "        Default is \"openai\".\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    langchain.chat_models.base.BaseChatModel\n",
        "        A chat model instance that can be invoked with messages.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    Initialize an OpenAI model (requires API key):\n",
        "\n",
        "    >>> llm = get_llm(\"openai\")\n",
        "    >>> llm.invoke(\"Hello, how are you?\")\n",
        "\n",
        "    Initialize a local Ollama model (e.g., Gemma2 2B):\n",
        "\n",
        "    >>> llm = get_llm(\"ollama\")\n",
        "    >>> llm.invoke(\"Summarize the benefits of reinforcement learning.\")\n",
        "    \"\"\"\n",
        "    if provider == \"openai\":\n",
        "        return ChatOpenAI(\n",
        "            model=\"gpt-4o-mini\",  # can also be \"gpt-4.1\" or \"gpt-4o\"\n",
        "            temperature=0\n",
        "        )\n",
        "    elif provider == \"ollama\":\n",
        "        return ChatOllama(\n",
        "            model=\"gemma2:2b\",   # replace with any local model installed in Ollama\n",
        "            temperature=0\n",
        "        )\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported provider. Use 'openai' or 'ollama'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sqlite3\n",
        "import pandas as pd\n",
        "\n",
        "# Create a small in-memory database\n",
        "conn = sqlite3.connect(\":memory:\")\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Example schema: customers and orders\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE customers (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    name TEXT,\n",
        "    country TEXT\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "cursor.execute(\"\"\"\n",
        "CREATE TABLE orders (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    customer_id INTEGER,\n",
        "    amount REAL,\n",
        "    FOREIGN KEY(customer_id) REFERENCES customers(id)\n",
        ")\n",
        "\"\"\")\n",
        "\n",
        "# Insert sample data\n",
        "customers = [(1, \"Alice\", \"Brazil\"), (2, \"Bob\", \"USA\"), (3, \"Charlie\", \"Brazil\")]\n",
        "orders = [(1, 1, 100.0), (2, 2, 200.0), (3, 1, 150.0)]\n",
        "cursor.executemany(\"INSERT INTO customers VALUES (?, ?, ?)\", customers)\n",
        "cursor.executemany(\"INSERT INTO orders VALUES (?, ?, ?)\", orders)\n",
        "conn.commit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1 — Inspect schema\n",
        "The schema is retrieved with `PRAGMA table_info` so the LLM can be informed about available tables and columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Database schema: {'customers': ['id', 'name', 'country'], 'orders': ['id', 'customer_id', 'amount']}\n"
          ]
        }
      ],
      "source": [
        "def get_schema(cursor):\n",
        "    schema = {}\n",
        "    for table in [\"customers\", \"orders\"]:\n",
        "        cursor.execute(f\"PRAGMA table_info({table});\")\n",
        "        schema[table] = [row[1] for row in cursor.fetchall()]\n",
        "    return schema\n",
        "\n",
        "schema = get_schema(cursor)\n",
        "print(\"Database schema:\", schema)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2 — Prompt LLM to generate SQL\n",
        "The LLM receives the schema and a question, and is instructed to output only SQL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Assume get_llm() was defined in Notebook 2\n",
        "llm = get_llm(\"openai\")  # or get_llm(\"ollama\")\n",
        "\n",
        "sql_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are an expert in SQL. Given a schema and a question, output only a SQL query.\"),\n",
        "    (\"human\", \"Schema: {schema}\\nQuestion: {question}\")\n",
        "])\n",
        "\n",
        "def generate_sql(question: str):\n",
        "    chain = sql_prompt | llm\n",
        "    return chain.invoke({\"schema\": schema, \"question\": question}).content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3 — Execute SQL with correction loop\n",
        "The query is executed with pandas. If it fails, the error message is passed back to the LLM for correction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_query(sql: str):\n",
        "    try:\n",
        "        return pd.read_sql_query(sql, conn)\n",
        "    except Exception as e:\n",
        "        return f\"Execution error: {e}\"\n",
        "\n",
        "def text_to_sql(question: str):\n",
        "    sql = generate_sql(question)\n",
        "    print(\"Generated SQL:\", sql)\n",
        "    result = run_query(sql)\n",
        "    if isinstance(result, str):  # error string\n",
        "        correction_prompt = f\"The SQL failed with error: {result}. Please suggest a corrected SQL query.\"\n",
        "        sql = llm.invoke([(\"human\", correction_prompt)]).content\n",
        "        print(\"Corrected SQL:\", sql)\n",
        "        result = run_query(sql)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4 — Try examples\n",
        "The pipeline is tested with natural language questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated SQL: ```sql\n",
            "SELECT name FROM customers WHERE country = 'Brazil';\n",
            "```\n",
            "Corrected SQL: The error you're encountering is due to the presence of the code block formatting (```sql) in your SQL query. SQL queries should not include these formatting markers. Here’s the corrected SQL query:\n",
            "\n",
            "```sql\n",
            "SELECT name FROM customers WHERE country = 'Brazil';\n",
            "```\n",
            "\n",
            "Make sure to run the query without the backticks and any additional formatting. Just use the SQL statement as it is shown above.\n",
            "Execution error: Execution failed on sql 'The error you're encountering is due to the presence of the code block formatting (```sql) in your SQL query. SQL queries should not include these formatting markers. Here’s the corrected SQL query:\n",
            "\n",
            "```sql\n",
            "SELECT name FROM customers WHERE country = 'Brazil';\n",
            "```\n",
            "\n",
            "Make sure to run the query without the backticks and any additional formatting. Just use the SQL statement as it is shown above.': near \"The\": syntax error\n"
          ]
        }
      ],
      "source": [
        "print(text_to_sql(\"List the names of all customers from Brazil.\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated SQL: ```sql\n",
            "SELECT c.id, c.name, SUM(o.amount) AS total_amount\n",
            "FROM customers c\n",
            "JOIN orders o ON c.id = o.customer_id\n",
            "GROUP BY c.id, c.name;\n",
            "```\n",
            "Corrected SQL: The error you're encountering is likely due to the presence of the code block formatting (the triple backticks) in your SQL query. SQL queries should not include these formatting characters. Here’s the corrected SQL query without the backticks:\n",
            "\n",
            "```sql\n",
            "SELECT c.id, c.name, SUM(o.amount) AS total_amount\n",
            "FROM customers c\n",
            "JOIN orders o ON c.id = o.customer_id\n",
            "GROUP BY c.id, c.name;\n",
            "```\n",
            "\n",
            "Make sure to run the query in your SQL environment without any additional formatting characters. If you still encounter issues, ensure that the table names (`customers` and `orders`) and the column names (`id`, `name`, `amount`, `customer_id`) are correct and exist in your database schema.\n",
            "Execution error: Execution failed on sql 'The error you're encountering is likely due to the presence of the code block formatting (the triple backticks) in your SQL query. SQL queries should not include these formatting characters. Here’s the corrected SQL query without the backticks:\n",
            "\n",
            "```sql\n",
            "SELECT c.id, c.name, SUM(o.amount) AS total_amount\n",
            "FROM customers c\n",
            "JOIN orders o ON c.id = o.customer_id\n",
            "GROUP BY c.id, c.name;\n",
            "```\n",
            "\n",
            "Make sure to run the query in your SQL environment without any additional formatting characters. If you still encounter issues, ensure that the table names (`customers` and `orders`) and the column names (`id`, `name`, `amount`, `customer_id`) are correct and exist in your database schema.': near \"The\": syntax error\n"
          ]
        }
      ],
      "source": [
        "print(text_to_sql(\"What is the total amount of orders per customer?\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reflection\n",
        "- Text-to-SQL pipelines require schema awareness, grounding values, and iterative correction.\n",
        "- The LLM handles translation from natural language → SQL, but verification is needed.\n",
        "- In real-world applications, more sophisticated schema linking and safety checks are necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercises\n",
        "1. Add a new table `products` and extend the schema. Ask multi-table questions.\n",
        "2. Force the LLM to output results in JSON instead of plain SQL.\n",
        "3. Replace `get_llm(\\\"openai\\\")` with `get_llm(\\\"ollama\\\")` to run with a local model."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sbbd2025_course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
