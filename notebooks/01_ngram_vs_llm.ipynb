{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# From Statistical Models to LLMs\n",
        "## Learning Goals\n",
        "- Understand how statistical n-gram models work.\n",
        "- Compare their limitations with modern LLMs.\n",
        "- See how context window size impacts predictions.\n",
        "- Experience emergent behaviors in transformer-based models.\n",
        "\n",
        "This notebook connects with Section *1.2 From Statistical Language Models to Neural-based LLMs* of the lecture notes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load a sample text corpus\n",
        "We’ll use the **Reuters dataset** from NLTK, which contains short news articles.  \n",
        "This will serve as training data for our n-gram models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to\n",
            "[nltk_data]     /Users/ebezerra/nltk_data...\n",
            "[nltk_data]   Package reuters is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /Users/ebezerra/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /Users/ebezerra/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of tokens: 142731\n",
            "Sample tokens: ['asian', 'exporters', 'fear', 'damage', 'from', 'u', '.', 's', '.-', 'japan', 'rift', 'mounting', 'trade', 'friction', 'between', 'the', 'u', '.', 's', '.', 'and', 'japan', 'has', 'raised', 'fears', 'among', 'many', 'of', 'asia', \"'\"]\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter, defaultdict\n",
        "import random\n",
        "\n",
        "nltk.download('reuters')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from nltk.corpus import reuters\n",
        "sentences = reuters.sents(categories='trade')\n",
        "tokens = [t.lower() for sent in sentences for t in sent]\n",
        "print('Number of tokens:', len(tokens))\n",
        "print('Sample tokens:', tokens[:30])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Build a simple n-gram model\n",
        "- A **bigram** model looks at the last 1 token.\n",
        "- A **trigram** model looks at the last 2 tokens.\n",
        "\n",
        "We’ll count frequencies and use them to predict the next word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bigram sample: 204 billion dlrs in the u . s . s . s . s . s . s . s .\n",
            "Trigram sample: products also was met . the u . s . trade deficit , which is being promoted mainly to help reduce its\n"
          ]
        }
      ],
      "source": [
        "def build_ngram_model(tokens, n=2):\n",
        "    model = defaultdict(Counter)\n",
        "    for i in range(len(tokens)-n):\n",
        "        context = tuple(tokens[i:i+n-1])\n",
        "        next_word = tokens[i+n-1]\n",
        "        model[context][next_word] += 1\n",
        "    return model\n",
        "\n",
        "bigram_model = build_ngram_model(tokens, n=2)\n",
        "trigram_model = build_ngram_model(tokens, n=3)\n",
        "\n",
        "def generate_text(model, n=2, length=20, seed=None):\n",
        "    if not seed:\n",
        "        seed = random.choice(list(model.keys()))\n",
        "    output = list(seed)\n",
        "    for _ in range(length):\n",
        "        context = tuple(output[-(n-1):])\n",
        "        if context not in model:\n",
        "            break\n",
        "        next_word = model[context].most_common(1)[0][0]\n",
        "        output.append(next_word)\n",
        "    return ' '.join(output)\n",
        "\n",
        "print('Bigram sample:', generate_text(bigram_model, n=2))\n",
        "print('Trigram sample:', generate_text(trigram_model, n=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reflection\n",
        "- Does the output feel natural or broken?\n",
        "- Notice how **short context** (bigram/trigram) limits coherence.\n",
        "- Try changing the `length` parameter and observe when it becomes gibberish."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Use a Transformer-based LLM (GPT-2)\n",
        "Now let’s compare with a pretrained HuggingFace model.  \n",
        "Unlike n-grams, GPT-2 has a context window of **1024 tokens** and was trained on a massive dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=50) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The future of artificial intelligence in databases is very exciting, and the Internet of Things (IoT) could revolutionize the way we conduct business.\n",
            "\n",
            "On the heels of the IoT ecosystem's emergence, companies are also now looking to bring out the best in their AI systems: through the Internet of Things (IoT). The world has now developed the ability to interact with artificial intelligence in real time, and with data stored on its behalf. The IoT ecosystem is a new frontier, and the internet of things could even be the next big thing.\n",
            "\n",
            "\"IoT is not a technology that is just going to happen in the next few years,\" says Martin Schulz, founder of the IoT Group. \"Rather, it's going to be a set of technologies that are going to allow companies to work together with AI to develop new products and services.\"\n",
            "\n",
            "This is a very exciting time for IoT. The internet of things could become the true Internet of Things, with every new invention, industry, and technology going the way of the dodo.\n",
            "\n",
            "There's a lot to look forward to when we see that happen.\n",
            "\n",
            "Update: Martin Schulz has now published an article, \"The Internet of Things that Will Make Us Happy,\"\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "generator = pipeline('text-generation', model='gpt2', device=-1)  # device=-1 = CPU\n",
        "\n",
        "prompt = 'The future of artificial intelligence in databases'\n",
        "output = generator(prompt, max_length=50, num_return_sequences=1)\n",
        "print(output[0]['generated_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.26.4\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\"> Generated Text </span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ─────────────────────────────────────────────────</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[92m──────────────────────────────────────────────── \u001b[0m\u001b[1;34m Generated Text \u001b[0m\u001b[92m ─────────────────────────────────────────────────\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">The future of artificial intelligence in databases is very exciting, and the Internet of Things (IoT) could        \n",
              "revolutionize the way we conduct business.                                                                         \n",
              "\n",
              "On the heels of the IoT ecosystem's emergence, companies are also now looking to bring out the best in their AI    \n",
              "systems: through the Internet of Things (IoT). The world has now developed the ability to interact with artificial \n",
              "intelligence in real time, and with data stored on its behalf. The IoT ecosystem is a new frontier, and the        \n",
              "internet of things could even be the next big thing.                                                               \n",
              "\n",
              "\"IoT is not a technology that is just going to happen in the next few years,\" says Martin Schulz, founder of the   \n",
              "IoT Group. \"Rather, it's going to be a set of technologies that are going to allow companies to work together with \n",
              "AI to develop new products and services.\"                                                                          \n",
              "\n",
              "This is a very exciting time for IoT. The internet of things could become the true Internet of Things, with every  \n",
              "new invention, industry, and technology going the way of the dodo.                                                 \n",
              "\n",
              "There's a lot to look forward to when we see that happen.                                                          \n",
              "\n",
              "Update: Martin Schulz has now published an article, \"The Internet of Things that Will Make Us Happy,\"              \n",
              "</pre>\n"
            ],
            "text/plain": [
              "The future of artificial intelligence in databases is very exciting, and the Internet of Things (IoT) could        \n",
              "revolutionize the way we conduct business.                                                                         \n",
              "\n",
              "On the heels of the IoT ecosystem's emergence, companies are also now looking to bring out the best in their AI    \n",
              "systems: through the Internet of Things (IoT). The world has now developed the ability to interact with artificial \n",
              "intelligence in real time, and with data stored on its behalf. The IoT ecosystem is a new frontier, and the        \n",
              "internet of things could even be the next big thing.                                                               \n",
              "\n",
              "\"IoT is not a technology that is just going to happen in the next few years,\" says Martin Schulz, founder of the   \n",
              "IoT Group. \"Rather, it's going to be a set of technologies that are going to allow companies to work together with \n",
              "AI to develop new products and services.\"                                                                          \n",
              "\n",
              "This is a very exciting time for IoT. The internet of things could become the true Internet of Things, with every  \n",
              "new invention, industry, and technology going the way of the dodo.                                                 \n",
              "\n",
              "There's a lot to look forward to when we see that happen.                                                          \n",
              "\n",
              "Update: Martin Schulz has now published an article, \"The Internet of Things that Will Make Us Happy,\"              \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from rich.console import Console\n",
        "from rich.markdown import Markdown\n",
        "\n",
        "console = Console()\n",
        "text = output[0]['generated_text']\n",
        "\n",
        "console.rule(\"[bold blue] Generated Text [/bold blue]\")\n",
        "console.print(Markdown(text))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reflection\n",
        "- The GPT-2 output is more coherent, even though the model is relatively small.\n",
        "- Unlike n-grams, it can capture longer dependencies.\n",
        "- This illustrates the **scaling → emergent capabilities** phenomenon.\n",
        "\n",
        "## Exercises\n",
        "1. Train a 4-gram model and compare with the bigram/trigram. Does it improve coherence?\n",
        "2. Replace `gpt2` with a larger HuggingFace model (e.g., `distilgpt2`, `gpt2-medium`) and compare.\n",
        "3. Change the `prompt` and observe how the model continues your text."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sbbd2025_course",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
