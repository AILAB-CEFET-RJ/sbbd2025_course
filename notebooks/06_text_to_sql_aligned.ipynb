{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "339b929b",
   "metadata": {},
   "source": [
    "# 06 — Text-to-SQL (Aligned Pipeline)\n",
    "\n",
    "> **Course:** Introduction to LLM-Based Agents — SBBD 2025  \n",
    "> **Notebook goal:** Provide a didactic, step-by-step Text-to-SQL pipeline consistent with the course notes:  \n",
    "Intent Parsing → Schema Linking → Value Grounding → SQL Generation → Execution & Correction → Answer & Interactive Refinement.\n",
    "\n",
    "**Important:** The notebook is structured to be read and *then* run block-by-block. Some cells include placeholders (e.g., connection string, `get_llm()`), which must be adapted before execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd933b9",
   "metadata": {},
   "source": [
    "## Pipeline overview & checklist\n",
    "\n",
    "1. **Tool registration (SQL) & schema snapshot** — register the SQL connection and serialize a compact view of the schema for prompting.  \n",
    "2. **Intent Parsing** — extract a structured intent (task, entities, filters, time range, grouping, sorting, limit).  \n",
    "3. **Schema Linking** — retrieve candidate tables/columns and validate a minimal subgraph (tables, columns, join path).  \n",
    "4. **Value Grounding** — normalize temporal ranges and entity values to match the database contents.  \n",
    "5. **SQL Generation** — produce a single, safe `SELECT` query for the target dialect (with `LIMIT` fallback).  \n",
    "6. **Execution & Correction** — run the query; on error, feed the error back to the LLM and minimally correct the SQL.  \n",
    "7. **Answer & Interactive Refinement** — convert rows into a concise natural-language answer; if empty, propose a clarification.\n",
    "\n",
    "> The code is written with LangChain's `Runnable` API and a `get_llm()` factory to align with the course preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c0aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Dependencies — keep commented unless the environment needs installs.\n",
    "# !pip install langchain langchain-core langchain-community langchain-openai\n",
    "# !pip install sqlalchemy\n",
    "# !pip install faiss-cpu  # or 'chromadb' if preferred as retriever backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef2d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "# Core / typing\n",
    "from typing import List, Dict, Any, Optional, TypedDict\n",
    "import json\n",
    "from dataclasses import dataclass\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "# LangChain core\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "# LangChain community\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "# If using FAISS for catalog retrieval:\n",
    "# from langchain_community.vectorstores import FAISS\n",
    "# from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# NOTE: The function get_llm() is expected to be provided by the course utilities.\n",
    "# It should return a chat model compatible with LangChain Runnable (e.g., ChatOpenAI or ChatOllama)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "228e8ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load get_llm.py\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "def get_llm(provider: str = \"openai\"):\n",
    "    \"\"\"\n",
    "    Return a language model instance configured for either OpenAI or Ollama.\n",
    "\n",
    "    This function centralizes the initialization of chat-based LLMs so that \n",
    "    notebooks and applications can switch seamlessly between cloud-based models \n",
    "    (OpenAI) and local models (Ollama).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    provider : str, optional\n",
    "        The backend provider to use. Options are:\n",
    "        - \"openai\": returns a ChatOpenAI instance (requires OPENAI_API_KEY in .env).\n",
    "        - \"ollama\": returns a ChatOllama instance (requires Ollama installed locally).\n",
    "        Default is \"openai\".\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    langchain.chat_models.base.BaseChatModel\n",
    "        A chat model instance that can be invoked with messages.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    Initialize an OpenAI model (requires API key):\n",
    "\n",
    "    >>> llm = get_llm(\"openai\")\n",
    "    >>> llm.invoke(\"Hello, how are you?\")\n",
    "\n",
    "    Initialize a local Ollama model (e.g., Gemma2 2B):\n",
    "\n",
    "    >>> llm = get_llm(\"ollama\")\n",
    "    >>> llm.invoke(\"Summarize the benefits of reinforcement learning.\")\n",
    "    \"\"\"\n",
    "    if provider == \"openai\":\n",
    "        return ChatOpenAI(\n",
    "            model=\"gpt-4o-mini\",  # can also be \"gpt-4.1\" or \"gpt-4o\"\n",
    "            temperature=0\n",
    "        )\n",
    "    elif provider == \"ollama\":\n",
    "        return ChatOllama(\n",
    "            model=\"gemma2:2b\",   # replace with any local model installed in Ollama\n",
    "            temperature=0\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported provider. Use 'openai' or 'ollama'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae90f82",
   "metadata": {},
   "source": [
    "## 0) Tool registration (SQL) & schema snapshot\n",
    "\n",
    "Provide a DB connection (`DB_URI`) and create a compact, text-based schema snapshot for prompting. The snapshot should include:\n",
    "- table names, column names and types,\n",
    "- primary/foreign keys and obvious relationships,\n",
    "- a few example values for categorical columns (optional but recommended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f7f4fc3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SQLDatabase' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m DB_URI \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///./tickets.sqlite\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# --- Connect (no execution at import time) ---\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m db \u001b[38;5;241m=\u001b[39m \u001b[43mSQLDatabase\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_uri(DB_URI)\n\u001b[1;32m      7\u001b[0m SCHEMA_MAX_COLS_PER_TABLE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m\n\u001b[1;32m      8\u001b[0m EXAMPLE_ROWS_PER_COLUMN \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SQLDatabase' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Configuration ---\n",
    "DB_URI = \"sqlite:///./tickets.sqlite\"\n",
    "\n",
    "# --- Connect (no execution at import time) ---\n",
    "db = SQLDatabase.from_uri(DB_URI)\n",
    "\n",
    "SCHEMA_MAX_COLS_PER_TABLE = 12\n",
    "EXAMPLE_ROWS_PER_COLUMN = 3\n",
    "\n",
    "def introspect_schema(db: SQLDatabase,\n",
    "                      max_cols_per_table: int = SCHEMA_MAX_COLS_PER_TABLE,\n",
    "                      examples_per_col: int = EXAMPLE_ROWS_PER_COLUMN) -> str:\n",
    "    \"\"\"Return a compact text representation of the schema for prompting.\n",
    "    Implementation may query sqlite_master / information_schema under the hood through SQLDatabase.\n",
    "    Keep it short and readable.\n",
    "    \"\"\"\n",
    "    # Pseudocode sketch — adjust to your dialect if needed:\n",
    "    # tables = db.get_usable_table_names()\n",
    "    # lines = []\n",
    "    # for t in tables:\n",
    "    #     cols = db.run(f\"PRAGMA table_info({t})\")  # SQLite example; use proper INFO schema for other DBs\n",
    "    #     lines.append(f\"TABLE {t}:\")\n",
    "    #     for c in cols[:max_cols_per_table]:\n",
    "    #         lines.append(f\"  - {c['name']} ({c['type']})\")\n",
    "    #     # Optionally: example values (head) for categorical columns\n",
    "    # return \"\\n\".join(lines)\n",
    "    return \"\"  # Placeholder to keep the notebook runnable until DB is configured.\n",
    "\n",
    "# Example (leave commented until DB is available):\n",
    "# schema_text = introspect_schema(db)\n",
    "# print(schema_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce8a57b",
   "metadata": {},
   "source": [
    "## 1) Intent Parsing\n",
    "\n",
    "Extract a structured intent from the user question. The model must return **only** the requested JSON schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da120e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentDict(TypedDict):\n",
    "    task: str             # e.g., 'select', 'count', 'aggregate', 'topk'\n",
    "    entities: List[str]   # conceptual entities (e.g., 'customers', 'tickets')\n",
    "    measures: List[str]   # numeric fields or aggregations (e.g., 'sum(total)')\n",
    "    filters: Dict[str, Any]\n",
    "    time_range: Dict[str, Any]  # e.g., {'relative': 'last_month'} or {'start': '2025-06-01', 'end': '2025-06-30'}\n",
    "    group_by: List[str]\n",
    "    order_by: List[str]\n",
    "    limit: int\n",
    "\n",
    "intent_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"\"\"Extract a database intent as strict JSON with keys:\n",
    "     task, entities, measures, filters, time_range, group_by, order_by, limit.\n",
    "     Return **ONLY** the JSON object, with null for unknown fields.\"\"\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "# parse_intent = intent_prompt | get_llm().with_structured_output(IntentDict)  # To be enabled after get_llm()\n",
    "\n",
    "# Example usage (keep commented):\n",
    "# user_question = \"How many tickets were closed last month?\"\n",
    "# intent: IntentDict = parse_intent.invoke({\"question\": user_question})\n",
    "# print(intent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40254239",
   "metadata": {},
   "source": [
    "## 2) Schema Linking\n",
    "\n",
    "Create a textual catalog of `table.column – type – notes` entries, use embeddings to retrieve candidates, then validate a **minimal subgraph** (tables, columns, join path) via LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcd7808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_catalog_documents(schema_text: str) -> List[str]:\n",
    "    \"\"\"Split the schema snapshot into small, retrievable chunks (1 per column or section).\n",
    "    Return a list of short strings.\n",
    "    \"\"\"\n",
    "    if not schema_text:\n",
    "        return []\n",
    "    # Simple splitter (improve as needed):\n",
    "    docs = [line.strip() for line in schema_text.splitlines() if line.strip()]\n",
    "    return docs\n",
    "\n",
    "def summarize_candidates(candidates: List[Any], max_len: int = 1200) -> str:\n",
    "    \"\"\"Concatenate top-k candidate snippets into a single string for the validator LLM.\"\"\"\n",
    "    text = \"\\n\".join(getattr(c, \"page_content\", str(c)) for c in candidates)\n",
    "    return text[:max_len]\n",
    "\n",
    "link_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"\"\"You are validating schema usage for Text-to-SQL.\n",
    "Given the candidates below and the question, list ONLY:\n",
    "- relevant tables,\n",
    "- relevant columns per table,\n",
    "- the minimal join path (as pairs table.col -> table.col),\n",
    "in a compact JSON with keys {tables, columns, joins}. Return only JSON.\"\"\"),\n",
    "    (\"user\", \"Question: {question}\\n\\nCandidates:\\n{cands}\")\n",
    "])\n",
    "\n",
    "# Example (commented until retriever is configured):\n",
    "# embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# vs = FAISS.from_texts(build_catalog_documents(schema_text), embedder)\n",
    "# schema_retriever = vs.as_retriever(search_kwargs={\"k\": 12})\n",
    "# candidates = schema_retriever.get_relevant_documents(user_question)\n",
    "# linked_schema = (link_prompt | get_llm()).invoke({\"question\": user_question, \"cands\": summarize_candidates(candidates)})\n",
    "# print(linked_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af36a07b",
   "metadata": {},
   "source": [
    "## 3) Value Grounding\n",
    "\n",
    "Normalize temporal ranges and map entity names to existing values before generating SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31e352e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_bounds(ref: date) -> tuple[date, date]:\n",
    "    start = ref.replace(day=1)\n",
    "    if start.month == 12:\n",
    "        end = start.replace(year=start.year+1, month=1, day=1) - timedelta(days=1)\n",
    "    else:\n",
    "        end = start.replace(month=start.month+1, day=1) - timedelta(days=1)\n",
    "    return start, end\n",
    "\n",
    "def normalize_time(time_range: Optional[Dict[str, Any]], ref_date: Optional[date] = None) -> Dict[str, str]:\n",
    "    \"\"\"Map relative time ranges to explicit YYYY-MM-DD bounds.\"\"\"\n",
    "    if ref_date is None:\n",
    "        ref_date = date.today()\n",
    "    if not time_range:\n",
    "        return {}\n",
    "    rel = str(time_range.get(\"relative\", \"\")).lower()\n",
    "    if rel == \"last_month\":\n",
    "        first_of_this = ref_date.replace(day=1)\n",
    "        last_month_end = first_of_this - timedelta(days=1)\n",
    "        start, end = last_month_end.replace(day=1), last_month_end\n",
    "        return {\"start\": start.isoformat(), \"end\": end.isoformat()}\n",
    "    if {\"start\", \"end\"}.issubset(time_range.keys()):\n",
    "        return {\"start\": str(time_range[\"start\"]), \"end\": str(time_range[\"end\"])}\n",
    "    return {}\n",
    "\n",
    "def lookup_entities(entities: List[str], db: Optional[SQLDatabase], linked_schema_json: Any) -> Dict[str, Any]:\n",
    "    \"\"\"Attempt to ground entity strings to actual DB values.\n",
    "    Implementation here is a placeholder; typical approach:\n",
    "      - For each entity-like field found in linked_schema_json, sample distinct values and fuzzy-match.\n",
    "    \"\"\"\n",
    "    grounded = {}\n",
    "    # Example stub — extend with real queries over `db`:\n",
    "    for e in entities or []:\n",
    "        grounded[e] = {\"matched\": e, \"confidence\": 0.5}\n",
    "    return grounded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7efbff",
   "metadata": {},
   "source": [
    "## 4) SQL Generation (guardrails)\n",
    "\n",
    "Generate a single `SELECT` query for the chosen dialect, using only the linked schema and grounded values. Enforce safe defaults:\n",
    "- **No** DDL/DML or multiple statements,\n",
    "- add `LIMIT` if missing,\n",
    "- include a short SQL comment with the intent summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d868a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sql_block(text: str) -> str:\n",
    "    \"\"\"Extract the SQL code block from an LLM response; return raw SQL string.\"\"\"\n",
    "    if text is None:\n",
    "        return \"\"\n",
    "    fence = \"```\"\n",
    "    if fence in text:\n",
    "        inner = text.split(fence)\n",
    "        # Try to pick the first fenced block\n",
    "        for i in range(len(inner)-1):\n",
    "            candidate = inner[i+1]\n",
    "            # strip leading sql identifier (e.g., 'sql\\n')\n",
    "            candidate = candidate.split(\"\\n\", 1)[-1]\n",
    "            if \";\" in candidate or \"SELECT\" in candidate.upper():\n",
    "                return candidate.strip()\n",
    "    return text.strip()\n",
    "\n",
    "sql_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"\"\"You are a SQL generator. Follow STRICT rules:\n",
    "- Use ONLY the provided linked schema: {linked}\n",
    "- Respect grounded values: {grounded}\n",
    "- Task intent (JSON): {intent}\n",
    "- Dialect: {dialect}\n",
    "- Generate exactly one SELECT statement (no DDL/DML, no multiple statements).\n",
    "- If LIMIT is unspecified, add LIMIT {default_limit}.\n",
    "- Add a leading SQL comment with a one-line intent summary.\"\"\"),\n",
    "    (\"user\", \"{question}\")\n",
    "])\n",
    "\n",
    "# generate_sql = sql_prompt | get_llm() | RunnableLambda(extract_sql_block)  # Enable after get_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266b53cb",
   "metadata": {},
   "source": [
    "## 5) Execution & Correction loop\n",
    "\n",
    "Run the SQL. On error, provide the error message to the LLM and request a **minimal correction** using the same linked schema and grounded values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562e370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sql(db: SQLDatabase, sql: str) -> tuple[list[dict], Optional[str]]:\n",
    "    try:\n",
    "        rows = db.run(sql)\n",
    "        # `db.run` often returns a list of tuples; convert to dicts if column names are available.\n",
    "        # This is dialect/driver-dependent; adapt as needed.\n",
    "        return rows, None\n",
    "    except Exception as e:\n",
    "        return [], str(e)\n",
    "\n",
    "fix_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"\"\"The previous SQL failed with the error below. Return a minimal corrected SQL.\n",
    "- Keep the SAME intent and grounded values.\n",
    "- Use ONLY the same linked schema.\n",
    "- Return a single SELECT statement.\n",
    "Error: {error}\"\"\"),\n",
    "    (\"user\", \"Original SQL:\\n{sql}\")\n",
    "])\n",
    "\n",
    "def correction_loop(db: SQLDatabase, sql: str, linked: str, intent: Dict[str, Any],\n",
    "                    grounded: Dict[str, Any], dialect: str = \"PostgreSQL\",\n",
    "                    max_retries: int = 2, default_limit: int = 100) -> tuple[str, list[dict], Optional[str]]:\n",
    "    rows, err = run_sql(db, sql)\n",
    "    if not err:\n",
    "        return sql, rows, None\n",
    "    for _ in range(max_retries):\n",
    "        # repaired = (fix_prompt | get_llm() | RunnableLambda(extract_sql_block)).invoke(\n",
    "        #     {\"error\": err, \"sql\": sql, \"linked\": linked,\n",
    "        #      \"intent\": json.dumps(intent), \"grounded\": json.dumps(grounded),\n",
    "        #      \"dialect\": dialect, \"default_limit\": default_limit}\n",
    "        # )\n",
    "        repaired = sql  # placeholder to keep structure; replace with the line above.\n",
    "        rows, err = run_sql(db, repaired)\n",
    "        sql = repaired\n",
    "        if not err:\n",
    "            break\n",
    "    return sql, rows, err"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df2230c",
   "metadata": {},
   "source": [
    "## 6) Answer & Interactive Refinement\n",
    "\n",
    "Convert result rows into a concise natural-language answer; when the result is empty, propose a clarifying question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17fa298",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"\"\"Summarize the SQL result into a concise, neutral answer.\n",
    "Include the time window and key filters if available.\n",
    "If there are no rows, propose a short clarifying question.\"\"\"),\n",
    "    (\"user\", \"Rows (JSON): {rows}\\nIntent: {intent}\\nGrounded: {grounded}\")\n",
    "])\n",
    "\n",
    "# final_answer = (answer_prompt | get_llm())  # Enable after get_llm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7640f716",
   "metadata": {},
   "source": [
    "### (Optional) Create a tiny SQLite demo\n",
    "\n",
    "This cell creates a miniature dataset for quick local tests. Keep it commented in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98544eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sqlite3\n",
    "# conn = sqlite3.connect(\"./tickets.sqlite\")\n",
    "# cur = conn.cursor()\n",
    "# cur.execute(\"CREATE TABLE IF NOT EXISTS tickets (id INTEGER PRIMARY KEY, status TEXT, closed_date TEXT);\")\n",
    "# cur.execute(\"DELETE FROM tickets;\")\n",
    "# cur.executemany(\"INSERT INTO tickets (id, status, closed_date) VALUES (?, ?, ?);\", [\n",
    "#     (1, \"closed\", \"2025-08-05\"),\n",
    "#     (2, \"open\",   None),\n",
    "#     (3, \"closed\", \"2025-08-22\"),\n",
    "# ])\n",
    "# conn.commit(); conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3398634",
   "metadata": {},
   "source": [
    "## End-to-end driver (commented)\n",
    "\n",
    "The following cell shows the end-to-end sequence. Uncomment after wiring `get_llm()` and setting `DB_URI`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ca2fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_question = \"How many tickets were closed last month?\"\n",
    "#\n",
    "# # 0) Tool registration\n",
    "# db = SQLDatabase.from_uri(DB_URI)\n",
    "# schema_text = introspect_schema(db)\n",
    "#\n",
    "# # 1) Intent\n",
    "# parse_intent = intent_prompt | get_llm().with_structured_output(IntentDict)\n",
    "# intent: IntentDict = parse_intent.invoke({\"question\": user_question})\n",
    "#\n",
    "# # 2) Schema Linking\n",
    "# # (build retriever)\n",
    "# # embedder = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# # vs = FAISS.from_texts(build_catalog_documents(schema_text), embedder)\n",
    "# # schema_retriever = vs.as_retriever(search_kwargs={\"k\": 12})\n",
    "# # candidates = schema_retriever.get_relevant_documents(user_question)\n",
    "# # linked_schema = (link_prompt | get_llm()).invoke({\n",
    "# #     \"question\": user_question, \"cands\": summarize_candidates(candidates)\n",
    "# # })\n",
    "#\n",
    "# linked_schema = \"{}\"  # temporary if retriever is not configured\n",
    "#\n",
    "# # 3) Value Grounding\n",
    "# grounded = {\n",
    "#     \"time_range\": normalize_time(intent.get(\"time_range\"), ref_date=date(2025, 9, 1)),\n",
    "#     \"entities\": lookup_entities(intent.get(\"entities\"), db if 'db' in locals() else None, linked_schema)\n",
    "# }\n",
    "#\n",
    "# # 4) SQL Generation\n",
    "# generate_sql = sql_prompt | get_llm() | RunnableLambda(extract_sql_block)\n",
    "# sql = generate_sql.invoke({\n",
    "#     \"linked\": linked_schema, \"grounded\": json.dumps(grounded),\n",
    "#     \"intent\": json.dumps(intent), \"dialect\": \"SQLite\", \"default_limit\": 100,\n",
    "#     \"question\": user_question\n",
    "# })\n",
    "#\n",
    "# # 5) Execute & correct\n",
    "# final_sql, rows, err = correction_loop(db, sql, linked_schema, intent, grounded, dialect=\"SQLite\")\n",
    "#\n",
    "# # 6) Answer\n",
    "# # final_answer_chain = answer_prompt | get_llm()\n",
    "# # answer = final_answer_chain.invoke({\n",
    "# #     \"rows\": json.dumps(rows), \"intent\": json.dumps(intent), \"grounded\": json.dumps(grounded)\n",
    "# # })\n",
    "# # print(answer)\n",
    "#\n",
    "# print(\"SQL:\\n\", final_sql)\n",
    "# print(\"Rows:\\n\", rows)\n",
    "# print(\"Error:\\n\", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3eb050d",
   "metadata": {},
   "source": [
    "## Notes & tips\n",
    "\n",
    "- Keep the schema snapshot **short**; prune aggressively to minimize prompt tokens.  \n",
    "- Persist intermediate artifacts (intent JSON, linked schema JSON, grounded values) for debugging.  \n",
    "- In academic demos, add a short `-- intent:` comment line at the top of the generated SQL to aid students' understanding.  \n",
    "- Cap retries in the correction loop and log `(SQL → error → fix)` history for transparency."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sbbd2025_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
